#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - ãƒ•ã‚©ãƒ³ãƒˆã‹ã‚‰æ–‡å­—ç”»åƒã‚’æŠ½å‡º
"""

import argparse
import json
import sys
from pathlib import Path
from typing import List
import logging
from tqdm import tqdm
import numpy as np
from PIL import Image

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.font_parser import FontParser
from src.preprocessing import Preprocessor
from src.char_sets import get_characters, get_available_charsets

logger = logging.getLogger(__name__)


def prepare_data(
    font_dir: str,
    output_dir: str,
    characters: str,
    image_size: int = 128,
    train_split: float = 0.8,
    val_split: float = 0.1,
    test_split: float = 0.1,
    num_workers: int = 1,
):
    """
    ãƒ•ã‚©ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™

    Args:
        font_dir (str): ãƒ•ã‚©ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir (str): å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        characters (str): æ–‡å­—ã‚»ãƒƒãƒˆåï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
        image_size (int): ç”»åƒã‚µã‚¤ã‚º
        train_split (float): è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡
        val_split (float): æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡
        test_split (float): ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡
        num_workers (int): ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
    """
    font_dir = Path(font_dir)
    output_dir = Path(output_dir)

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_dir.mkdir(parents=True, exist_ok=True)
    (output_dir / "train").mkdir(exist_ok=True)
    (output_dir / "val").mkdir(exist_ok=True)
    if test_split > 0:
        (output_dir / "test").mkdir(exist_ok=True)

    # æ–‡å­—ã‚»ãƒƒãƒˆå–å¾—
    char_list = get_characters(characters)
    logger.info(f"Target characters: {len(char_list)}")

    # ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å–å¾— (å¤§æ–‡å­—ãƒ»å°æ–‡å­—ä¸¡æ–¹å¯¾å¿œ)
    font_files = (
        list(font_dir.glob("*.ttf")) +
        list(font_dir.glob("*.TTF")) +
        list(font_dir.glob("*.otf")) +
        list(font_dir.glob("*.OTF"))
    )
    logger.info(f"Found {len(font_files)} font files")

    if len(font_files) == 0:
        logger.error(f"No font files found in {font_dir}")
        return

    # å‰å‡¦ç†å™¨
    preprocessor = Preprocessor(image_size=image_size)

    # ãƒ•ã‚©ãƒ³ãƒˆæƒ…å ±ã‚’åé›†
    font_info = []
    all_characters = set()

    print("\nğŸ“‹ ãƒ•ã‚©ãƒ³ãƒˆæƒ…å ±ã‚’åé›†ä¸­...")
    for font_file in tqdm(font_files, desc="Scanning fonts"):
        try:
            parser = FontParser(str(font_file), image_size=image_size)
            available_chars = parser.get_available_characters(char_list)

            if len(available_chars) > 0:
                font_info.append(
                    {
                        "path": font_file,
                        "name": parser.font_name,
                        "available_chars": available_chars,
                    }
                )
                all_characters.update(available_chars)

            parser.close()

        except Exception as e:
            logger.warning(f"Failed to load {font_file.name}: {e}")

    logger.info(f"Valid fonts: {len(font_info)}")
    logger.info(f"Total characters: {len(all_characters)}")

    if len(font_info) == 0:
        logger.error("No valid fonts found")
        return

    # ãƒ•ã‚©ãƒ³ãƒˆã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
    print("\nğŸ¨ æ–‡å­—ç”»åƒã‚’ç”Ÿæˆä¸­...")

    # å˜ä¸€ãƒ•ã‚©ãƒ³ãƒˆã®å ´åˆã¯æ–‡å­—ã‚’åˆ†å‰²ã€è¤‡æ•°ãƒ•ã‚©ãƒ³ãƒˆã®å ´åˆã¯ãƒ•ã‚©ãƒ³ãƒˆã‚’åˆ†å‰²
    single_font_mode = len(font_info) == 1

    if single_font_mode:
        logger.info("Single font detected - splitting characters instead of fonts")

        # æ–‡å­—ã‚’train/val/testã«åˆ†å‰²
        font_data = font_info[0]
        available_chars = list(font_data["available_chars"])
        np.random.shuffle(available_chars)

        n_train = int(len(available_chars) * train_split)
        n_val = int(len(available_chars) * val_split)

        train_chars = available_chars[:n_train]
        val_chars = available_chars[n_train : n_train + n_val]
        test_chars = available_chars[n_train + n_val :] if test_split > 0 else []

        logger.info(f"Character split - Train: {len(train_chars)}, Val: {len(val_chars)}, Test: {len(test_chars)}")

        # å„splitã«åŒã˜ãƒ•ã‚©ãƒ³ãƒˆã‚’å‰²ã‚Šå½“ã¦ã‚‹ãŒã€æ–‡å­—ã‚’åˆ†ã‘ã‚‹
        splits = [
            ("train", [{"path": font_data["path"], "name": font_data["name"], "available_chars": train_chars}]),
            ("val", [{"path": font_data["path"], "name": font_data["name"], "available_chars": val_chars}]),
            ("test", [{"path": font_data["path"], "name": font_data["name"], "available_chars": test_chars}] if test_split > 0 else []),
        ]
    else:
        # ãƒ•ã‚©ãƒ³ãƒˆã‚’train/val/testã«åˆ†å‰²ï¼ˆå¾“æ¥ã®å‹•ä½œï¼‰
        np.random.shuffle(font_info)

        n_train = int(len(font_info) * train_split)
        n_val = int(len(font_info) * val_split)

        train_fonts = font_info[:n_train]
        val_fonts = font_info[n_train : n_train + n_val]
        test_fonts = font_info[n_train + n_val :] if test_split > 0 else []

        splits = [
            ("train", train_fonts),
            ("val", val_fonts),
            ("test", test_fonts),
        ]

    for split_name, split_fonts in splits:
        if len(split_fonts) == 0:
            continue

        logger.info(f"\nProcessing {split_name} split ({len(split_fonts)} fonts)...")

        for font_data in tqdm(split_fonts, desc=f"  {split_name}"):
            font_path = font_data["path"]
            font_name = font_data["name"]
            available_chars = font_data["available_chars"]

            # ãƒ•ã‚©ãƒ³ãƒˆåã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã¨ã—ã¦ä½¿ç”¨ï¼‰
            safe_font_name = "".join(
                c if c.isalnum() or c in ("-", "_") else "_" for c in font_name
            )

            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            font_output_dir = output_dir / split_name / safe_font_name
            font_output_dir.mkdir(parents=True, exist_ok=True)

            try:
                parser = FontParser(str(font_path), image_size=image_size)

                # æ–‡å­—ã‚’æç”»
                for char in available_chars:
                    try:
                        # ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
                        image = parser.render_character(char)

                        # å‰å‡¦ç†
                        processed = preprocessor.normalize_image(
                            image, center=True, invert=True
                        )

                        # ä¿å­˜
                        output_path = font_output_dir / f"{char}.png"
                        Image.fromarray((processed * 255).astype(np.uint8)).save(
                            output_path
                        )

                    except Exception as e:
                        logger.warning(f"Failed to process '{char}': {e}")

                parser.close()

            except Exception as e:
                logger.warning(f"Failed to process font {font_name}: {e}")

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    if single_font_mode:
        metadata = {
            "image_size": image_size,
            "num_fonts": 1,
            "single_font_mode": True,
            "num_train_chars": len(train_chars),
            "num_val_chars": len(val_chars),
            "num_test_chars": len(test_chars),
            "characters": sorted(list(all_characters)),
            "train_chars": sorted(train_chars),
            "val_chars": sorted(val_chars),
            "test_chars": sorted(test_chars),
            "font_name": font_info[0]["name"],
        }
    else:
        metadata = {
            "image_size": image_size,
            "num_fonts": len(font_info),
            "single_font_mode": False,
            "num_train_fonts": len(train_fonts),
            "num_val_fonts": len(val_fonts),
            "num_test_fonts": len(test_fonts),
            "characters": sorted(list(all_characters)),
            "fonts": [f["name"] for f in font_info],
            "train_fonts": [f["name"] for f in train_fonts],
            "val_fonts": [f["name"] for f in val_fonts],
            "test_fonts": [f["name"] for f in test_fonts],
        }

    metadata_path = output_dir / "metadata.json"
    with open(metadata_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    logger.info(f"\nâœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†!")
    logger.info(f"  å‡ºåŠ›å…ˆ: {output_dir}")
    if single_font_mode:
        logger.info(f"  ãƒ¢ãƒ¼ãƒ‰: å˜ä¸€ãƒ•ã‚©ãƒ³ãƒˆï¼ˆæ–‡å­—åˆ†å‰²ï¼‰")
        logger.info(f"  ãƒ•ã‚©ãƒ³ãƒˆ: {font_info[0]['name']}")
        logger.info(f"  æ–‡å­—æ•°: {len(all_characters)}")
        logger.info(f"    - Train: {len(train_chars)}")
        logger.info(f"    - Val: {len(val_chars)}")
        logger.info(f"    - Test: {len(test_chars)}")
    else:
        logger.info(f"  ãƒ¢ãƒ¼ãƒ‰: è¤‡æ•°ãƒ•ã‚©ãƒ³ãƒˆ")
        logger.info(f"  ãƒ•ã‚©ãƒ³ãƒˆæ•°: {len(font_info)}")
        logger.info(f"    - Train: {len(train_fonts)}")
        logger.info(f"    - Val: {len(val_fonts)}")
        logger.info(f"    - Test: {len(test_fonts)}")
        logger.info(f"  æ–‡å­—æ•°: {len(all_characters)}")
    logger.info(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata_path}")


def main():
    parser = argparse.ArgumentParser(description="ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")

    parser.add_argument(
        "--font-dir",
        type=str,
        required=True,
        help="ãƒ•ã‚©ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        required=True,
        help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
    )

    parser.add_argument(
        "--characters",
        type=str,
        default="hiragana,katakana",
        help=f"æ–‡å­—ã‚»ãƒƒãƒˆ (åˆ©ç”¨å¯èƒ½: {', '.join(get_available_charsets())})",
    )

    parser.add_argument(
        "--image-size",
        type=int,
        default=128,
        help="ç”»åƒã‚µã‚¤ã‚º (default: 128)",
    )

    parser.add_argument(
        "--train-split",
        type=float,
        default=0.8,
        help="è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡ (default: 0.8)",
    )

    parser.add_argument(
        "--val-split",
        type=float,
        default=0.1,
        help="æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡ (default: 0.1)",
    )

    parser.add_argument(
        "--test-split",
        type=float,
        default=0.1,
        help="ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡ (default: 0.1)",
    )

    parser.add_argument(
        "--num-workers",
        type=int,
        default=1,
        help="ãƒ¯ãƒ¼ã‚«ãƒ¼æ•° (default: 1)",
    )

    parser.add_argument(
        "--log-level",
        type=str,
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«",
    )

    args = parser.parse_args()

    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=getattr(logging, args.log_level),
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    # ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Ÿè¡Œ
    prepare_data(
        font_dir=args.font_dir,
        output_dir=args.output_dir,
        characters=args.characters,
        image_size=args.image_size,
        train_split=args.train_split,
        val_split=args.val_split,
        test_split=args.test_split,
        num_workers=args.num_workers,
    )


if __name__ == "__main__":
    main()
