#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import argparse
import json
import sys
from pathlib import Path
import random
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

sys.path.insert(0, str(Path(__file__).parent.parent))


def visualize_dataset(data_dir: str, output_path: str, num_samples: int = 25):
    """
    ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¯è¦–åŒ–

    Args:
        data_dir (str): ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_path (str): å‡ºåŠ›ç”»åƒãƒ‘ã‚¹
        num_samples (int): ã‚µãƒ³ãƒ—ãƒ«æ•°
    """
    data_dir = Path(data_dir)

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    metadata_path = data_dir / "metadata.json"
    if not metadata_path.exists():
        print(f"Error: Metadata not found: {metadata_path}")
        return

    with open(metadata_path, "r", encoding="utf-8") as f:
        metadata = json.load(f)

    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±:")
    print(f"  ãƒ•ã‚©ãƒ³ãƒˆæ•°: {metadata['num_fonts']}")
    print(f"    - Train: {metadata['num_train_fonts']}")
    print(f"    - Val: {metadata['num_val_fonts']}")
    print(f"    - Test: {metadata['num_test_fonts']}")
    print(f"  æ–‡å­—æ•°: {len(metadata['characters'])}")
    print(f"  ç”»åƒã‚µã‚¤ã‚º: {metadata['image_size']}x{metadata['image_size']}")

    # ã‚µãƒ³ãƒ—ãƒ«ã‚’åé›†
    train_dir = data_dir / "train"
    if not train_dir.exists():
        print(f"Error: Train directory not found: {train_dir}")
        return

    samples = []
    for font_dir in train_dir.iterdir():
        if not font_dir.is_dir():
            continue

        image_files = list(font_dir.glob("*.png"))
        if len(image_files) > 0:
            # ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤é¸æŠ
            image_path = random.choice(image_files)
            char = image_path.stem
            samples.append((image_path, char, font_dir.name))

    if len(samples) == 0:
        print("Error: No samples found")
        return

    # ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’åˆ¶é™
    if len(samples) > num_samples:
        samples = random.sample(samples, num_samples)

    # ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
    grid_size = int(np.ceil(np.sqrt(num_samples)))

    # å¯è¦–åŒ–
    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))
    axes = axes.flatten()

    for idx, (image_path, char, font_name) in enumerate(samples):
        if idx >= len(axes):
            break

        # ç”»åƒèª­ã¿è¾¼ã¿
        image = Image.open(image_path).convert("L")

        axes[idx].imshow(image, cmap="gray")
        axes[idx].set_title(f"'{char}'\n{font_name[:15]}", fontsize=8)
        axes[idx].axis("off")

    # æ®‹ã‚Šã®è»¸ã‚’éè¡¨ç¤º
    for idx in range(len(samples), len(axes)):
        axes[idx].axis("off")

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches="tight")
    print(f"\nâœ… å¯è¦–åŒ–ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")


def main():
    parser = argparse.ArgumentParser(description="ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")

    parser.add_argument(
        "--data-dir",
        type=str,
        required=True,
        help="ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
    )

    parser.add_argument(
        "--output",
        type=str,
        default="data_visualization.png",
        help="å‡ºåŠ›ç”»åƒãƒ‘ã‚¹ (default: data_visualization.png)",
    )

    parser.add_argument(
        "--num-samples",
        type=int,
        default=25,
        help="ã‚µãƒ³ãƒ—ãƒ«æ•° (default: 25)",
    )

    args = parser.parse_args()

    visualize_dataset(
        data_dir=args.data_dir,
        output_path=args.output,
        num_samples=args.num_samples,
    )


if __name__ == "__main__":
    main()
